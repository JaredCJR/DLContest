{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import tensorflow as tf\n",
    "\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "import re\n",
    "\n",
    "import string\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import random\n",
    "import time\n",
    "from tqdm import trange\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 6375 vocabularies in total\n",
      "Word to id mapping, for example: flower -> 2428\n",
      "Id to word mapping, for example: 2428 -> flower\n",
      "Tokens: <PAD>: 6372; <RARE>: 6374\n"
     ]
    }
   ],
   "source": [
    "dictionary_path = './dictionary'\n",
    "vocab = np.load(dictionary_path + '/vocab.npy')\n",
    "print('there are {} vocabularies in total'.format(len(vocab)))\n",
    "\n",
    "word2Id_dict = dict(np.load(dictionary_path + '/word2Id.npy'))\n",
    "id2word_dict = dict(np.load(dictionary_path + '/id2Word.npy'))\n",
    "print('Word to id mapping, for example: %s -> %s' % ('flower',\n",
    "                                                     word2Id_dict['flower']))\n",
    "print('Id to word mapping, for example: %s -> %s' % ('2428',\n",
    "                                                     id2word_dict['2428']))\n",
    "print('Tokens: <PAD>: %s; <RARE>: %s' % (word2Id_dict['<PAD>'],\n",
    "                                         word2Id_dict['<RARE>']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798\n",
      "1784\n"
     ]
    }
   ],
   "source": [
    "print (word2Id_dict['<ST>'])\n",
    "print (word2Id_dict['<ED>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7370 image in training data\n"
     ]
    }
   ],
   "source": [
    "data_path = './dataset'\n",
    "df = pd.read_pickle(data_path + '/text2ImgData.pkl')\n",
    "num_training_sample = len(df)\n",
    "n_images_train = num_training_sample\n",
    "print('There are %d image in training data' % (n_images_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7370 image in training data\n"
     ]
    }
   ],
   "source": [
    "df_img = df['ImagePath'].values\n",
    "print('There are %d image in training data' % (len(df_img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caption = df['Captions'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2435', '2428', '2505', '2431', '2444', '2427', '2433', '2434', '2530', '2444', '2449', '6372', '6372', '6372', '6372', '6372', '6372', '6372', '6372', '6372'], ['2430', '2428', '2431', '2427', '2436', '2432', '2444', '2429', '2510', '2448', '6372', '6372', '6372', '6372', '6372', '6372', '6372', '6372', '6372', '6372'], ['2430', '2428', '2431', '2451', '2429', '3361', '2468', '2427', '2433', '2483', '2461', '2439', '2696', '2503', '2445', '2444', '2429', '2611', '6372', '6372'], ['2430', '2442', '2434', '2452', '2428', '2433', '2451', '2444', '2427', '2453', '2467', '6372', '6372', '6372', '6372', '6372', '6372', '6372', '6372', '6372'], ['2435', '2428', '2431', '2427', '2436', '2432', '2487', '2444', '2433', '2434', '2449', '2522', '2448', '2427', '6372', '6372', '6372', '6372', '6372', '6372'], ['2430', '2428', '2431', '2444', '2429', '2440', '2427', '2436', '2527', '2434', '2510', '2448', '6372', '6372', '6372', '6372', '6372', '6372', '6372', '6372'], ['2430', '2428', '2431', '2434', '2462', '2444', '2478', '2559', '2433', '2434', '2444', '2547', '2448', '2427', '2480', '2467', '2449', '6372', '6372', '6372'], ['2518', '2428', '2432', '2444', '2433', '2451', '2576', '2427', '2429', '2729', '2449', '6372', '6372', '6372', '6372', '6372', '6372', '6372', '6372', '6372'], ['2430', '2428', '2431', '2451', '2444', '2729', '2427', '2429', '2462', '2447', '2459', '6372', '6372', '6372', '6372', '6372', '6372', '6372', '6372', '6372']]\n"
     ]
    }
   ],
   "source": [
    "print (df_caption[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7370/7370 [00:00<00:00, 22762.28it/s]\n"
     ]
    }
   ],
   "source": [
    "d_captions = []\n",
    "for i in trange(len(df_caption)):\n",
    "    caps = []\n",
    "    for caption in df_caption[i]:\n",
    "        cap = []\n",
    "        cap.append(word2Id_dict['<ST>'])\n",
    "        for word in caption:\n",
    "            cap.append(word)\n",
    "        cap.append(word2Id_dict['<ED>'])\n",
    "        caps.append(cap)\n",
    "    d_captions.append(caps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(7370,)\n"
     ]
    }
   ],
   "source": [
    "d_captions = np.asarray(d_captions)\n",
    "print (type(df_img))\n",
    "print (d_captions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Captions</th>\n",
       "      <th>ImagePath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[798, 2430, 2428, 2431, 2427, 2436, 2432, 245...</td>\n",
       "      <td>/102flowers/image_08110.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[798, 2430, 2428, 2431, 2427, 2436, 2432, 244...</td>\n",
       "      <td>/102flowers/image_07749.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[798, 2435, 2428, 2505, 2431, 2444, 2427, 243...</td>\n",
       "      <td>/102flowers/image_04381.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[798, 2430, 2428, 2431, 2563, 2437, 2427, 243...</td>\n",
       "      <td>/102flowers/image_04518.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[798, 2435, 2428, 2427, 2432, 5409, 2429, 243...</td>\n",
       "      <td>/102flowers/image_07620.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[798, 2430, 2428, 2442, 2450, 2439, 2441, 243...</td>\n",
       "      <td>/102flowers/image_00724.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[798, 2428, 2433, 2438, 2427, 2429, 2487, 244...</td>\n",
       "      <td>/102flowers/image_00550.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[798, 2430, 2428, 2442, 2438, 2439, 2441, 243...</td>\n",
       "      <td>/102flowers/image_07209.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[798, 2428, 2431, 2427, 2436, 2432, 2440, 243...</td>\n",
       "      <td>/102flowers/image_02334.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[798, 2518, 2428, 2470, 2451, 2510, 2448, 242...</td>\n",
       "      <td>/102flowers/image_07389.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Captions  \\\n",
       "0  [[798, 2430, 2428, 2431, 2427, 2436, 2432, 245...   \n",
       "1  [[798, 2430, 2428, 2431, 2427, 2436, 2432, 244...   \n",
       "2  [[798, 2435, 2428, 2505, 2431, 2444, 2427, 243...   \n",
       "3  [[798, 2430, 2428, 2431, 2563, 2437, 2427, 243...   \n",
       "4  [[798, 2435, 2428, 2427, 2432, 5409, 2429, 243...   \n",
       "5  [[798, 2430, 2428, 2442, 2450, 2439, 2441, 243...   \n",
       "6  [[798, 2428, 2433, 2438, 2427, 2429, 2487, 244...   \n",
       "7  [[798, 2430, 2428, 2442, 2438, 2439, 2441, 243...   \n",
       "8  [[798, 2428, 2431, 2427, 2436, 2432, 2440, 243...   \n",
       "9  [[798, 2518, 2428, 2470, 2451, 2510, 2448, 242...   \n",
       "\n",
       "                     ImagePath  \n",
       "0  /102flowers/image_08110.jpg  \n",
       "1  /102flowers/image_07749.jpg  \n",
       "2  /102flowers/image_04381.jpg  \n",
       "3  /102flowers/image_04518.jpg  \n",
       "4  /102flowers/image_07620.jpg  \n",
       "5  /102flowers/image_00724.jpg  \n",
       "6  /102flowers/image_00550.jpg  \n",
       "7  /102flowers/image_07209.jpg  \n",
       "8  /102flowers/image_02334.jpg  \n",
       "9  /102flowers/image_07389.jpg  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = pd.DataFrame({\n",
    "    'Captions': d_captions,\n",
    "    'ImagePath': df_img                \n",
    "})\n",
    "\n",
    "df_.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Captions</th>\n",
       "      <th>ImagePath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>[[2430, 2428, 2431, 2427, 2436, 2432, 2450, 24...</td>\n",
       "      <td>/102flowers/image_08110.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6790</th>\n",
       "      <td>[[2430, 2428, 2431, 2427, 2436, 2432, 2440, 24...</td>\n",
       "      <td>/102flowers/image_07749.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7908</th>\n",
       "      <td>[[2435, 2428, 2505, 2431, 2444, 2427, 2433, 24...</td>\n",
       "      <td>/102flowers/image_04381.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>[[2430, 2428, 2431, 2563, 2437, 2427, 2433, 24...</td>\n",
       "      <td>/102flowers/image_04518.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>[[2435, 2428, 2427, 2432, 5409, 2429, 2432, 24...</td>\n",
       "      <td>/102flowers/image_07620.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>[[2430, 2428, 2442, 2450, 2439, 2441, 2433, 24...</td>\n",
       "      <td>/102flowers/image_00724.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4679</th>\n",
       "      <td>[[2428, 2433, 2438, 2427, 2429, 2487, 2440, 36...</td>\n",
       "      <td>/102flowers/image_00550.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880</th>\n",
       "      <td>[[2430, 2428, 2442, 2438, 2439, 2441, 2433, 24...</td>\n",
       "      <td>/102flowers/image_07209.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>[[2428, 2431, 2427, 2436, 2432, 2440, 2433, 24...</td>\n",
       "      <td>/102flowers/image_02334.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5771</th>\n",
       "      <td>[[2518, 2428, 2470, 2451, 2510, 2448, 2427, 24...</td>\n",
       "      <td>/102flowers/image_07389.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Captions  \\\n",
       "1855  [[2430, 2428, 2431, 2427, 2436, 2432, 2450, 24...   \n",
       "6790  [[2430, 2428, 2431, 2427, 2436, 2432, 2440, 24...   \n",
       "7908  [[2435, 2428, 2505, 2431, 2444, 2427, 2433, 24...   \n",
       "1805  [[2430, 2428, 2431, 2563, 2437, 2427, 2433, 24...   \n",
       "5679  [[2435, 2428, 2427, 2432, 5409, 2429, 2432, 24...   \n",
       "432   [[2430, 2428, 2442, 2450, 2439, 2441, 2433, 24...   \n",
       "4679  [[2428, 2433, 2438, 2427, 2429, 2487, 2440, 36...   \n",
       "4880  [[2430, 2428, 2442, 2438, 2439, 2441, 2433, 24...   \n",
       "2164  [[2428, 2431, 2427, 2436, 2432, 2440, 2433, 24...   \n",
       "5771  [[2518, 2428, 2470, 2451, 2510, 2448, 2427, 24...   \n",
       "\n",
       "                        ImagePath  \n",
       "1855  /102flowers/image_08110.jpg  \n",
       "6790  /102flowers/image_07749.jpg  \n",
       "7908  /102flowers/image_04381.jpg  \n",
       "1805  /102flowers/image_04518.jpg  \n",
       "5679  /102flowers/image_07620.jpg  \n",
       "432   /102flowers/image_00724.jpg  \n",
       "4679  /102flowers/image_00550.jpg  \n",
       "4880  /102flowers/image_07209.jpg  \n",
       "2164  /102flowers/image_02334.jpg  \n",
       "5771  /102flowers/image_07389.jpg  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.to_csv(data_path + '/text_ImgPath.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iterator_rnn(filenames, batch_size):\n",
    "    captions = df_['Captions'].values\n",
    "    caption = []\n",
    "    \n",
    "    for _ in range(3):\n",
    "        for i in range(len(captions)):\n",
    "            caption.append(random.choice(captions[i]))\n",
    "    caption = np.asarray(caption)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((caption))\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    output_types = dataset.output_types\n",
    "    output_shapes = dataset.output_shapes\n",
    "    \n",
    "    return iterator, output_types, output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnn(object):\n",
    "    def __init__(self, hparas, training_phase=True, reuse=False, return_embed=False):\n",
    "        self.hparas = hparas\n",
    "        self.training_phase = training_phase\n",
    "        self.return_embed = return_embed\n",
    "        self.reuse = reuse\n",
    "        self.sess = tf.Session()\n",
    "        \n",
    "        self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        \n",
    "        with tf.variable_scope('rnnftxt', reuse=self.reuse):\n",
    "            # if self.training_phase:\n",
    "            self.word_embed_matrix = tf.get_variable(\n",
    "                'rnn/wordembed',\n",
    "                shape=(self.hparas['VOCAB_SIZE'], self.hparas['EMBED_DIM']),\n",
    "                initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                dtype=tf.float32)\n",
    "            #else:\n",
    "            #    self.word_embed_matrix = tf.Variable(self.embed_matrix)\n",
    "                \n",
    "            self.text = tf.placeholder(dtype=tf.int64, shape=[hparas['BATCH_SIZE'], None], name='caption')\n",
    "            embedded_word_ids = tf.nn.embedding_lookup(self.word_embed_matrix, self.text)\n",
    "            embedded_word_ref = tf.nn.embedding_lookup(self.word_embed_matrix, self.text)\n",
    "            \n",
    "            # seq = tf.one_hot(self.seq, 22)\n",
    "        with tf.variable_scope('rnncell', reuse=self.reuse):\n",
    "            LSTMCell = tf.contrib.rnn.BasicLSTMCell(\n",
    "                self.hparas['TEXT_DIM'],\n",
    "                reuse=self.reuse)\n",
    "            initial_state = LSTMCell.zero_state(\n",
    "                self.hparas['BATCH_SIZE'],\n",
    "                dtype=tf.float32)\n",
    "            rnn_net = tf.nn.dynamic_rnn(\n",
    "                cell=LSTMCell,\n",
    "                inputs=embedded_word_ids,\n",
    "                initial_state=initial_state,\n",
    "                dtype=tf.float32,\n",
    "                time_major=False,\n",
    "                scope='rnn/dynamic')\n",
    "            self.rnn_net = rnn_net\n",
    "            self.outputs_last = rnn_net[0][:, -1, :]\n",
    "            self.outputs = rnn_net[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.training_phase:\n",
    "            with tf.variable_scope('rnn/logits'):\n",
    "                self.logits = tf.contrib.layers.fully_connected(\n",
    "                    self.outputs, \n",
    "                    self.hparas['TEXT_DIM'], \n",
    "                    None)\n",
    "                \n",
    "            with tf.variable_scope('rnn/loss'):\n",
    "                self.loss = tf.reduce_sum(\n",
    "                    tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=self.logits[:, :-1], \n",
    "                    labels=embedded_word_ref[:, 1:]))\n",
    "            \n",
    "            with tf.variable_scope('rnn/optim'):\n",
    "                self.optim = tf.train.AdamOptimizer(self.hparas['LR'], beta1=self.hparas['BETA']) \\\n",
    "                                        .minimize(self.loss)\n",
    "            \n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.global_step = tf.train.get_or_create_global_step()\n",
    "        self.sess.run(tf.global_variables_initializer()) \n",
    "            \n",
    "        \n",
    "    def train(self, iterator_train):\n",
    "        \n",
    "        self.sess.run(iterator_train.initializer)\n",
    "        \n",
    "        self.losses = []\n",
    "        for _epoch in trange(self.hparas['N_EPOCH']):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            for _step in range(100):\n",
    "                next_element = iterator_train.get_next()\n",
    "                text = self.sess.run(next_element)\n",
    "                \n",
    "                loss, _ = self.sess.run([self.loss, self.optim],\n",
    "                                        feed_dict={\n",
    "                                            self.text: text\n",
    "                                        })\n",
    "                epoch_loss += loss\n",
    "            self.losses.append(epoch_loss)\n",
    "            \n",
    "        self.save(self.global_step)\n",
    "        \n",
    "    def inference(self, text):\n",
    "        output_embedded = self.sess.run(self.outputs_last, feed_dict={self.text: text})\n",
    "        return output_embedded\n",
    "        \n",
    "    \n",
    "    def save(self, global_step):\n",
    "        gs = global_step.eval(self.sess)\n",
    "        self.saver.save(self.sess, 'model/' + 'preTrainRnn.ckpt', global_step=gs)\n",
    "\n",
    "    def restore(self):\n",
    "        ckpt = tf.train.get_checkpoint_state('./model')\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            print (ckpt.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, ckpt.model_checkpoint_path)\n",
    "        return self.sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hparas():\n",
    "    hparas = {\n",
    "        'MAX_SEQ_LENGTH': 22,\n",
    "        'EMBED_DIM': 64,  # word embedding dimension\n",
    "        'VOCAB_SIZE': len(vocab),\n",
    "        'TEXT_DIM': 64,  # text embrdding dimension\n",
    "        'RNN_HIDDEN_SIZE': 64,\n",
    "        'Z_DIM': 64,  # random noise z dimension\n",
    "        'IMAGE_SIZE': [64, 64, 3],  # render image size\n",
    "        'BATCH_SIZE': 64,\n",
    "        'LR': 0.00002,\n",
    "        'DECAY_EVERY': 100,\n",
    "        'LR_DECAY': 0.5,\n",
    "        'BETA': 0.5,  # AdamOptimizer parameter\n",
    "        'N_EPOCH': 100,\n",
    "        'N_SAMPLE': num_training_sample\n",
    "    }\n",
    "    return hparas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [47:55<00:00, 37.57s/it]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "BATCH_SIZE = 64\n",
    "iterator_train, types, shapes = data_iterator_rnn(\n",
    "    data_path + '/text2ImgData.pkl', BATCH_SIZE)\n",
    "# iter_initializer = iterator_train.initializer\n",
    "\n",
    "hparas = get_hparas()\n",
    "caption = tf.placeholder(dtype=tf.int64, shape=[hparas['BATCH_SIZE'], None], name='caption')\n",
    "text_encoder = Rnn(hparas=hparas, training_phase=True, reuse=False)\n",
    "\n",
    "text_encoder.train(iterator_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEDCAYAAADdpATdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nX0QkAin8RUQi0P8DjoljgpBQgsUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9e40f52080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_loss = plt.plot([text_encoder.losses[i] for i in range(len(text_encoder.losses))])\n",
    "plt.legend(['Loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hparas = get_hparas()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "t2 = Rnn(hparas=hparas, training_phase=False, reuse=False)\n",
    "t2.restore()\n",
    "\n",
    "# assert(t2.word_embed_matrix == text_encoder.word_embed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "iterator_train, types, shapes = data_iterator_rnn(\n",
    "    data_path + '/text2ImgData.pkl', BATCH_SIZE)\n",
    "\n",
    "iter_initializer = iterator_train.initializer\n",
    "next_element = iterator_train.get_next()\n",
    "t2.sess.run(iter_initializer)\n",
    "text = t2.sess.run(next_element)\n",
    "output = t2.sess.run(t2.outputs_last, feed_dict={t2.text: text})\n",
    "    \n",
    "print (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ot = t2.inference(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(ot.shape[0]):\n",
    "    for k in range(ot.shape[1]):\n",
    "        assert (ot[i][k] == output[i][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (range(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb = tf.Variable(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(eb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert (t2.word_embed_matrix == eb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (eb.shape)\n",
    "print (t2.word_embed_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t2.sess.close()\n",
    "text_encoder.sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
