{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from wordPreprocess import WordPreprocess\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 100000 of lines\n",
      "Finished 200000 of lines\n",
      "Finished 300000 of lines\n",
      "Finished 400000 of lines\n",
      "Finished 500000 of lines\n",
      "Finished 600000 of lines\n",
      "Finished 700000 of lines\n",
      "Finished 800000 of lines\n",
      "Finished 900000 of lines\n",
      "Finished 1000000 of lines\n",
      "Finished 1100000 of lines\n",
      "Finished 1200000 of lines\n",
      "Finished 1300000 of lines\n",
      "Finished 1400000 of lines\n",
      "Finished 1500000 of lines\n",
      "Finished 1600000 of lines\n",
      "Finished 1700000 of lines\n",
      "Finished 1800000 of lines\n",
      "Finished 1900000 of lines\n",
      "Finished 2000000 of lines\n",
      "Finished 2100000 of lines\n",
      "Finished 2200000 of lines\n",
      "Finished 2300000 of lines\n",
      "Finished 2400000 of lines\n"
     ]
    }
   ],
   "source": [
    "programs_questions = []\n",
    "num_lines = 0\n",
    "with open('program_quesiton.txt', 'r') as inFile:\n",
    "    for line in inFile:\n",
    "        programs_questions.append(line.strip('\\n'))\n",
    "        num_lines += 1\n",
    "        \n",
    "        if num_lines % 100000 == 0:\n",
    "            print (\"Finished %d of lines\" % num_lines)\n",
    "\n",
    "word2vec_model = word2vec.Word2Vec.load('word2vec_model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word_preprocess = WordPreprocess()\n",
    "doc_hash = word_preprocess.hash_transform(programs_questions, num_feature=2**7)\n",
    "print (doc_hash.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_vec = []\n",
    "\n",
    "for sentence in programs_questions:\n",
    "    words = sentence.split(' ')[:-1]\n",
    "    vec = np.zeros(shape=(250,), dtype=float)\n",
    "    count = 0\n",
    "    for w in words:\n",
    "        try:\n",
    "            vec += word2vec_model.wv[w]\n",
    "            count += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    #if (count > 0):\n",
    "    #    vec /= count\n",
    "    doc_vec.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "programs = programs_questions[:2396906]\n",
    "questions = programs_questions[2396906:]\n",
    "\n",
    "programs_vec = doc_vec[:2396906]\n",
    "questions_vec = doc_vec[2396906:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_training_data():\n",
    "    Xs, Ys = [], []\n",
    "    NUM_TRAIN = 500000\n",
    "    itr = 0\n",
    "    \n",
    "    while (itr < NUM_TRAIN):\n",
    "        pos_or_neg = random.randint(0,1)\n",
    "        \n",
    "        if pos_or_neg is 1:\n",
    "            line_id = random.randint(0, len(programs)-1)\n",
    "            \n",
    "            L1 = programs[line_id].split(' ')[:-1]\n",
    "            L2 = programs[line_id+1].split(' ')[:-1]\n",
    "            \n",
    "            if (not not L1 and not not L2):\n",
    "                try:\n",
    "                    Ys.append(word2vec_model.n_similarity(L1, L2))\n",
    "                    Xs.append([programs_vec[line_id], programs_vec[line_id+1]])\n",
    "                    itr += 1\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            \n",
    "        else:\n",
    "            line1_id = random.randint(0, len(programs)-1)\n",
    "            line2_id = random.randint(0, len(programs)-1)\n",
    "            \n",
    "            L1 = programs[line1_id].split(' ')[:-1]\n",
    "            L2 = programs[line2_id].split(' ')[:-1]\n",
    "            \n",
    "            if (not not L1 and not not L2):\n",
    "                try:\n",
    "                    Ys.append(word2vec_model.n_similarity(L1, L2))\n",
    "                    Xs.append([programs_vec[line1_id], programs_vec[line2_id]])\n",
    "                    itr += 1\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            \n",
    "    return Xs, Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -71.24503981  -39.82789333   -0.57092833 ...,  -15.1777363    19.54160349\n",
      "     5.17705814]\n",
      " [ -31.39640256   -6.64013747  -25.63856923 ...,  -14.89299984\n",
      "     8.25296802   33.90197016]\n",
      " [ -60.07967457   -8.35876344  -17.65124545 ...,  -37.0523163    24.38538967\n",
      "     1.38797454]\n",
      " ..., \n",
      " [ -59.95008327    3.16324217   37.43261593 ...,  -40.55259431    4.5161483\n",
      "    50.96414012]\n",
      " [-110.90598182   -4.07486932  -30.11510022 ...,  -42.238529      8.9708259\n",
      "   106.16224528]\n",
      " [ -60.70204079   41.25366257 -141.51711863 ..., -100.92373302\n",
      "    26.05217959  123.96008004]]\n"
     ]
    }
   ],
   "source": [
    "X, y = generate_training_data()\n",
    "\n",
    "X_ = []\n",
    "\n",
    "\n",
    "for t in X:\n",
    "    X_.append(np.dot(t[0], t[1])*t[1]/np.linalg.norm(t[1]))\n",
    "\n",
    "X_ = np.stack(X_, axis=0)\n",
    "print (X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ = []\n",
    "for t in X:\n",
    "    X_.append(np.dot(t[0], t[1])*t[0]/np.linalg.norm(t[0]))\n",
    "    \n",
    "X_ = np.stack(X_, axis=0)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1|5]\n",
      "MSE: 0.0214\n",
      "[Fold 2|5]\n",
      "MSE: 0.0194\n",
      "[Fold 3|5]\n",
      "MSE: 0.0193\n",
      "[Fold 4|5]\n",
      "MSE: 0.0200\n",
      "[Fold 5|5]\n",
      "MSE: 0.0192\n",
      "Best MSE: 0.0192 in 4th fold\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sys\n",
    "\n",
    "cv5 = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "cv5_score = []\n",
    "best_score = sys.float_info.max\n",
    "best_i = -1\n",
    "clfs = {}\n",
    "\n",
    "for i, (train, valid) in enumerate(cv5.split(X_, y)):\n",
    "    X_train, X_valid = X_[train], X_[valid]\n",
    "    y_train, y_valid = y[train], y[valid]\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_valid_std = sc.transform(X_valid)\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    \n",
    "    y_pred_lr = lr.predict(X_valid_std)\n",
    "    cv5_score.append(mean_squared_error(y_valid, y_pred_lr))\n",
    "    clfs[i] = lr\n",
    "    if mean_squared_error(y_valid, y_pred_lr) < best_score:\n",
    "        best_score, best_i = mean_squared_error(y_valid, y_pred_lr), i\n",
    "        \n",
    "for j, score in enumerate(cv5_score):\n",
    "    print (\"[Fold %d|5]\" % (j+1))\n",
    "    print (\"MSE: %.4f\" % score)\n",
    "    \n",
    "print (\"Best MSE: %.4f in %dth fold\" % (best_score, best_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = generate_training_data()\n",
    "\n",
    "X_ = []\n",
    "\n",
    "for t in X:\n",
    "    X_.append(np.dot(t[0], t[1])*t[1]/np.linalg.norm(t[1]))\n",
    "    \n",
    "\n",
    "X_ = np.stack(X_, axis=0)\n",
    "print (X_)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_valid_std = sc.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression with jieba using big5_dict gets best accuracy so far, accuracy: 0.368"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regr = LinearRegression()\n",
    "regr.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_valid_std)\n",
    "print(\"MSE: %f\" % mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "lr_rg = Ridge(alpha=1000)\n",
    "lr_rg.fit(X_train_std, y_train)\n",
    "    \n",
    "y_pred_rg = lr_rg.predict(X_valid_std)\n",
    "    \n",
    "print (\"MSE: %f\" % mean_squared_error(y_valid, y_pred_rg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm_rbf = SVC(kernel='rbf', random_state=0, C=10.0, gamma=0.2)\n",
    "svm_rbf.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred = svm_rbf.predict(X_valid_std)\n",
    "\n",
    "print (\"Accuracy: %.3f\" % (accuracy_score(y_valid, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree = DecisionTreeRegressor(max_depth=10)\n",
    "\n",
    "tree.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred_tree = tree.predict(X_valid_std)\n",
    "\n",
    "print (\"MSE: %f\" % mean_squared_error(y_valid, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "q_test = []\n",
    "for q_id in range(500):\n",
    "    question = questions_vec[q_id*7]\n",
    "    answer = 0\n",
    "    sim_max = sys.float_info.min\n",
    "    for i in range(1,7):\n",
    "        ans = questions_vec[q_id*7 + i]\n",
    "        #set_ = [x+y for x, y in zip(question, ans)]\n",
    "        set_ = np.dot(question, ans)*question/np.linalg.norm(question)\n",
    "        #set_ = np.array(set_)\n",
    "        result = clfs[best_i].predict(set_.reshape(1,-1))\n",
    "        if result > sim_max:\n",
    "            answer = i-1\n",
    "            sim_max = result\n",
    "        \n",
    "    q_test.append((q_id, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4), (1, 4), (2, 3), (3, 4), (4, 0), (5, 3), (6, 2), (7, 0), (8, 0), (9, 4), (10, 0), (11, 2), (12, 0), (13, 1), (14, 5), (15, 0), (16, 4), (17, 4), (18, 0), (19, 0), (20, 2), (21, 5), (22, 4), (23, 0), (24, 2), (25, 1), (26, 4), (27, 2), (28, 4), (29, 0), (30, 2), (31, 2), (32, 3), (33, 1), (34, 4), (35, 3), (36, 0), (37, 0), (38, 4), (39, 0), (40, 3), (41, 4), (42, 5), (43, 0), (44, 3), (45, 5), (46, 4), (47, 1), (48, 2), (49, 3), (50, 5), (51, 4), (52, 5), (53, 1), (54, 0), (55, 1), (56, 3), (57, 3), (58, 0), (59, 0), (60, 0), (61, 0), (62, 3), (63, 0), (64, 3), (65, 4), (66, 4), (67, 3), (68, 3), (69, 4), (70, 5), (71, 5), (72, 0), (73, 3), (74, 3), (75, 3), (76, 0), (77, 0), (78, 1), (79, 0), (80, 5), (81, 3), (82, 2), (83, 5), (84, 1), (85, 2), (86, 2), (87, 5), (88, 5), (89, 1), (90, 5), (91, 4), (92, 1), (93, 3), (94, 5), (95, 1), (96, 0), (97, 1), (98, 3), (99, 5), (100, 3), (101, 4), (102, 0), (103, 1), (104, 0), (105, 2), (106, 4), (107, 2), (108, 1), (109, 4), (110, 4), (111, 2), (112, 0), (113, 3), (114, 5), (115, 3), (116, 1), (117, 0), (118, 1), (119, 0), (120, 0), (121, 3), (122, 0), (123, 2), (124, 5), (125, 4), (126, 1), (127, 0), (128, 4), (129, 3), (130, 1), (131, 2), (132, 3), (133, 5), (134, 0), (135, 3), (136, 2), (137, 1), (138, 4), (139, 1), (140, 2), (141, 3), (142, 4), (143, 0), (144, 4), (145, 4), (146, 1), (147, 2), (148, 1), (149, 2), (150, 0), (151, 0), (152, 3), (153, 0), (154, 1), (155, 4), (156, 1), (157, 5), (158, 5), (159, 4), (160, 2), (161, 4), (162, 4), (163, 5), (164, 1), (165, 0), (166, 3), (167, 3), (168, 1), (169, 1), (170, 5), (171, 4), (172, 2), (173, 2), (174, 1), (175, 0), (176, 3), (177, 4), (178, 4), (179, 2), (180, 1), (181, 2), (182, 3), (183, 5), (184, 4), (185, 0), (186, 0), (187, 3), (188, 4), (189, 5), (190, 5), (191, 2), (192, 2), (193, 3), (194, 2), (195, 5), (196, 0), (197, 4), (198, 3), (199, 2), (200, 1), (201, 1), (202, 0), (203, 2), (204, 5), (205, 1), (206, 3), (207, 1), (208, 0), (209, 2), (210, 0), (211, 1), (212, 3), (213, 3), (214, 3), (215, 1), (216, 0), (217, 0), (218, 3), (219, 5), (220, 2), (221, 2), (222, 5), (223, 3), (224, 2), (225, 4), (226, 3), (227, 1), (228, 1), (229, 0), (230, 0), (231, 5), (232, 0), (233, 0), (234, 4), (235, 1), (236, 5), (237, 2), (238, 0), (239, 0), (240, 1), (241, 1), (242, 5), (243, 1), (244, 4), (245, 4), (246, 4), (247, 3), (248, 2), (249, 2), (250, 5), (251, 0), (252, 4), (253, 4), (254, 2), (255, 4), (256, 3), (257, 3), (258, 4), (259, 5), (260, 2), (261, 0), (262, 3), (263, 2), (264, 4), (265, 3), (266, 3), (267, 4), (268, 4), (269, 1), (270, 0), (271, 2), (272, 2), (273, 4), (274, 0), (275, 1), (276, 2), (277, 4), (278, 3), (279, 2), (280, 2), (281, 2), (282, 2), (283, 2), (284, 2), (285, 4), (286, 4), (287, 4), (288, 1), (289, 0), (290, 2), (291, 3), (292, 1), (293, 1), (294, 1), (295, 0), (296, 4), (297, 2), (298, 0), (299, 1), (300, 0), (301, 4), (302, 0), (303, 0), (304, 0), (305, 3), (306, 1), (307, 1), (308, 0), (309, 2), (310, 4), (311, 3), (312, 5), (313, 3), (314, 5), (315, 5), (316, 5), (317, 2), (318, 3), (319, 3), (320, 1), (321, 3), (322, 3), (323, 5), (324, 1), (325, 5), (326, 0), (327, 1), (328, 0), (329, 5), (330, 1), (331, 3), (332, 3), (333, 1), (334, 2), (335, 1), (336, 0), (337, 3), (338, 2), (339, 0), (340, 2), (341, 5), (342, 1), (343, 2), (344, 2), (345, 2), (346, 2), (347, 3), (348, 5), (349, 4), (350, 4), (351, 1), (352, 3), (353, 2), (354, 0), (355, 2), (356, 0), (357, 1), (358, 4), (359, 0), (360, 3), (361, 3), (362, 4), (363, 5), (364, 0), (365, 0), (366, 5), (367, 4), (368, 2), (369, 1), (370, 0), (371, 3), (372, 2), (373, 1), (374, 0), (375, 2), (376, 1), (377, 0), (378, 5), (379, 4), (380, 1), (381, 5), (382, 5), (383, 3), (384, 3), (385, 3), (386, 5), (387, 4), (388, 3), (389, 1), (390, 4), (391, 4), (392, 5), (393, 1), (394, 2), (395, 5), (396, 5), (397, 5), (398, 2), (399, 0), (400, 5), (401, 1), (402, 4), (403, 0), (404, 3), (405, 3), (406, 0), (407, 4), (408, 1), (409, 0), (410, 2), (411, 3), (412, 4), (413, 5), (414, 2), (415, 5), (416, 2), (417, 3), (418, 3), (419, 3), (420, 1), (421, 1), (422, 3), (423, 2), (424, 3), (425, 2), (426, 3), (427, 2), (428, 2), (429, 4), (430, 0), (431, 5), (432, 2), (433, 3), (434, 1), (435, 4), (436, 3), (437, 4), (438, 4), (439, 3), (440, 3), (441, 5), (442, 1), (443, 1), (444, 3), (445, 3), (446, 4), (447, 4), (448, 5), (449, 0), (450, 1), (451, 2), (452, 5), (453, 5), (454, 3), (455, 1), (456, 4), (457, 4), (458, 1), (459, 5), (460, 5), (461, 4), (462, 4), (463, 1), (464, 4), (465, 2), (466, 4), (467, 5), (468, 0), (469, 3), (470, 1), (471, 1), (472, 5), (473, 2), (474, 0), (475, 1), (476, 5), (477, 3), (478, 1), (479, 2), (480, 1), (481, 1), (482, 5), (483, 1), (484, 2), (485, 2), (486, 3), (487, 0), (488, 5), (489, 0), (490, 4), (491, 0), (492, 5), (493, 5), (494, 0), (495, 0), (496, 1), (497, 3), (498, 5), (499, 3)]\n"
     ]
    }
   ],
   "source": [
    "print (q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data=q_test, columns=['Id', 'Answer']).to_csv('Answer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
