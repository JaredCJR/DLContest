{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy: 0.496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 100000 of lines\n",
      "Finished 200000 of lines\n",
      "Finished 300000 of lines\n",
      "Finished 400000 of lines\n",
      "Finished 500000 of lines\n",
      "Finished 600000 of lines\n",
      "Finished 700000 of lines\n",
      "Finished 800000 of lines\n",
      "Finished 900000 of lines\n",
      "Finished 1000000 of lines\n",
      "Finished 1100000 of lines\n",
      "Finished 1200000 of lines\n",
      "Finished 1300000 of lines\n",
      "Finished 1400000 of lines\n",
      "Finished 1500000 of lines\n",
      "Finished 1600000 of lines\n",
      "Finished 1700000 of lines\n",
      "Finished 1800000 of lines\n",
      "Finished 1900000 of lines\n",
      "Finished 2000000 of lines\n",
      "Finished 2100000 of lines\n",
      "Finished 2200000 of lines\n",
      "Finished 2300000 of lines\n",
      "Finished 2400000 of lines\n"
     ]
    }
   ],
   "source": [
    "programs_questions = []\n",
    "num_lines = 0\n",
    "with open('program_question.txt', 'r') as inFile:\n",
    "    for line in inFile:\n",
    "        programs_questions.append(line.strip('\\n'))\n",
    "        num_lines += 1\n",
    "        \n",
    "        if num_lines % 100000 == 0:\n",
    "            print (\"Finished %d of lines\" % num_lines)\n",
    "            \n",
    "word2vec_model = word2vec.Word2Vec.load('word2vec_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "programs = programs_questions[:2396906]\n",
    "questions = programs_questions[2396906:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_training_data():\n",
    "    Xs, Ys = [], []\n",
    "    NUM_TRAIN = 300000\n",
    "    itr = 0\n",
    "    \n",
    "    while (itr < NUM_TRAIN):\n",
    "        pos_or_neg = random.randint(0, 1)\n",
    "        \n",
    "        if (pos_or_neg is 1):\n",
    "            line_id = random.randint(1, len(programs)-1)\n",
    "            \n",
    "            L1 = programs[line_id].split(' ')[:-1]\n",
    "            L2 = programs[line_id+1].split(' ')[:-1]\n",
    "            L3 = programs[line_id-1].split(' ')[:-1]\n",
    "            \n",
    "            if (L1 and L2 and L3):\n",
    "                try:\n",
    "                    sim1 = word2vec_model.n_similarity(L1, L2)\n",
    "                    sim2 = word2vec_model.n_similarity(L1, L3)\n",
    "                    if (sim1 > sim2):\n",
    "                        Ys.append(1)\n",
    "                        Xs.append(programs[line_id])\n",
    "                        Xs.append(programs[line_id+1])\n",
    "                    else:\n",
    "                        Ys.append(1)\n",
    "                        Xs.append(programs[line_id])\n",
    "                        Xs.append(programs[line_id-1])\n",
    "                    itr += 1\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                \n",
    "        else:\n",
    "            line1_id = random.randint(0, len(programs)-1)\n",
    "            line2_id = random.randint(0, len(programs)-1)\n",
    "            \n",
    "            L1 = programs[line1_id].split(' ')[:-1]\n",
    "            L2 = programs[line2_id].split(' ')[:-1]\n",
    "            \n",
    "            if (L1 and L2):\n",
    "                try:\n",
    "                    Ys.append(-1)\n",
    "                    Xs.append(programs[line1_id])\n",
    "                    Xs.append(programs[line2_id])\n",
    "                    itr += 1\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                \n",
    "    return Xs, Ys\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, y = generate_training_data()\n",
    "\n",
    "for question in questions:\n",
    "    data.append(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(3,4), sublinear_tf=True)\n",
    "tfidf.fit(data)\n",
    "\n",
    "doc_tf = tfidf.transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_vec = []\n",
    "\n",
    "for sentence, tf_idf in zip(data, doc_tf):\n",
    "    words = sentence.split(' ')[:-1]\n",
    "    vec = np.zeros(shape=(100,), dtype=float)\n",
    "    \n",
    "    for w in words:\n",
    "        try:\n",
    "            vec = np.add(vec, word2vec_model.wv[w]*tf_idf[tfidf.vocabulary_[w]])\n",
    "        except KeyError:\n",
    "            vec = np.add(vec, word2vec_model.wv[w]*0.000001)\n",
    "        \n",
    "    doc_vec.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "programs_vec = doc_vec[:600000]\n",
    "questions_vec = doc_vec[600000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600000\n",
      "3500\n"
     ]
    }
   ],
   "source": [
    "print (len(programs_vec))\n",
    "print (len(questions_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "X_ = []\n",
    "\n",
    "for _id in range(300000):\n",
    "    X_.append(np.dot(programs_vec[_id*2], programs_vec[_id*2+1])*programs_vec[_id*2]/np.linalg.norm(programs_vec[_id*2]))\n",
    "    \n",
    "X_ = np.stack(X_, axis=0)\n",
    "y = np.array(y)\n",
    "\n",
    "#for i, vec in enumerate(X_):\n",
    "#    for item in vec:\n",
    "#        x = float(item)\n",
    "#        if math.isnan(x):\n",
    "#            print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_, y, test_size=0.3, random_state=1)\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_valid_std = sc.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "a = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "best_mse = 100000\n",
    "best_a = -1\n",
    "\n",
    "for alpha in a:\n",
    "    las = Lasso(alpha=alpha)\n",
    "    \n",
    "    las.fit(X_train_std, y_train)\n",
    "    y_pred = las.predict(X_valid_std)\n",
    "    \n",
    "    if (mean_squared_error(y_valid, y_pred) < best_mse):\n",
    "        best_mse = mean_squared_error(y_valid, y_pred)\n",
    "        best_a = alpha\n",
    "        \n",
    "print (\"Best MSE: %.4f with alpha: %.4f\" % (best_mse, best_a))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las = Lasso(alpha=0.0001)\n",
    "\n",
    "las.fit(X_train_std, y_train)\n",
    "y_pred_las = las.predict(X_valid_std)\n",
    "\n",
    "print (\"MSE: %.4f\" % (mean_squared_error(y_valid, y_pred_las)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larry/Py3/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.8245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_std, y_train)\n",
    "y_pred_lr = lr.predict(X_valid_std)\n",
    "\n",
    "print (\"MSE: %.4f\" % (mean_squared_error(y_valid, y_pred_lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "q_test = []\n",
    "for q_id in range(500):\n",
    "    question = questions_vec[q_id*7]\n",
    "    answer = 0\n",
    "    sim_max = sys.float_info.min\n",
    "    for i in range(1,7):\n",
    "        ans = questions_vec[q_id*7 + i]\n",
    "        #set_ = [x+y for x, y in zip(question, ans)]\n",
    "        set_ = np.dot(question, ans)*question/np.linalg.norm(question)\n",
    "        #set_ = np.add(question, ans)\n",
    "        result = lr.predict(set_.reshape(1,-1))\n",
    "        if result > sim_max:\n",
    "            answer = i-1\n",
    "            sim_max = result\n",
    "        \n",
    "    q_test.append((q_id, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4), (1, 0), (2, 3), (3, 4), (4, 3), (5, 4), (6, 2), (7, 1), (8, 0), (9, 4), (10, 0), (11, 2), (12, 4), (13, 0), (14, 2), (15, 2), (16, 4), (17, 4), (18, 0), (19, 4), (20, 2), (21, 2), (22, 3), (23, 0), (24, 3), (25, 1), (26, 4), (27, 5), (28, 4), (29, 2), (30, 2), (31, 2), (32, 5), (33, 5), (34, 4), (35, 3), (36, 4), (37, 4), (38, 1), (39, 1), (40, 0), (41, 4), (42, 5), (43, 0), (44, 3), (45, 5), (46, 5), (47, 2), (48, 2), (49, 3), (50, 1), (51, 3), (52, 5), (53, 3), (54, 1), (55, 1), (56, 5), (57, 1), (58, 2), (59, 4), (60, 0), (61, 2), (62, 4), (63, 0), (64, 3), (65, 4), (66, 0), (67, 3), (68, 0), (69, 4), (70, 5), (71, 5), (72, 0), (73, 5), (74, 3), (75, 1), (76, 1), (77, 4), (78, 1), (79, 3), (80, 0), (81, 2), (82, 2), (83, 3), (84, 3), (85, 1), (86, 4), (87, 1), (88, 2), (89, 0), (90, 5), (91, 1), (92, 4), (93, 5), (94, 3), (95, 1), (96, 4), (97, 5), (98, 3), (99, 0), (100, 1), (101, 2), (102, 0), (103, 3), (104, 1), (105, 2), (106, 1), (107, 2), (108, 2), (109, 1), (110, 4), (111, 1), (112, 3), (113, 0), (114, 5), (115, 3), (116, 1), (117, 0), (118, 1), (119, 4), (120, 2), (121, 3), (122, 3), (123, 2), (124, 5), (125, 3), (126, 3), (127, 5), (128, 1), (129, 3), (130, 1), (131, 2), (132, 2), (133, 2), (134, 0), (135, 3), (136, 1), (137, 3), (138, 3), (139, 5), (140, 2), (141, 3), (142, 0), (143, 0), (144, 0), (145, 1), (146, 3), (147, 2), (148, 1), (149, 1), (150, 2), (151, 4), (152, 5), (153, 0), (154, 1), (155, 4), (156, 5), (157, 5), (158, 5), (159, 2), (160, 2), (161, 4), (162, 1), (163, 5), (164, 1), (165, 3), (166, 0), (167, 3), (168, 4), (169, 3), (170, 1), (171, 5), (172, 0), (173, 4), (174, 5), (175, 0), (176, 3), (177, 4), (178, 1), (179, 5), (180, 1), (181, 2), (182, 3), (183, 5), (184, 2), (185, 4), (186, 1), (187, 3), (188, 5), (189, 4), (190, 3), (191, 2), (192, 1), (193, 1), (194, 2), (195, 5), (196, 3), (197, 4), (198, 2), (199, 4), (200, 2), (201, 4), (202, 4), (203, 0), (204, 5), (205, 5), (206, 3), (207, 2), (208, 1), (209, 5), (210, 3), (211, 1), (212, 2), (213, 0), (214, 3), (215, 1), (216, 4), (217, 0), (218, 3), (219, 2), (220, 0), (221, 3), (222, 1), (223, 3), (224, 1), (225, 4), (226, 1), (227, 4), (228, 5), (229, 1), (230, 0), (231, 5), (232, 0), (233, 0), (234, 3), (235, 5), (236, 3), (237, 5), (238, 5), (239, 0), (240, 1), (241, 1), (242, 5), (243, 1), (244, 0), (245, 3), (246, 5), (247, 3), (248, 0), (249, 2), (250, 3), (251, 0), (252, 4), (253, 3), (254, 4), (255, 4), (256, 3), (257, 3), (258, 1), (259, 0), (260, 1), (261, 1), (262, 3), (263, 1), (264, 4), (265, 3), (266, 3), (267, 4), (268, 0), (269, 1), (270, 0), (271, 2), (272, 1), (273, 0), (274, 5), (275, 3), (276, 3), (277, 2), (278, 4), (279, 2), (280, 2), (281, 3), (282, 2), (283, 0), (284, 3), (285, 2), (286, 4), (287, 4), (288, 5), (289, 0), (290, 2), (291, 5), (292, 1), (293, 1), (294, 1), (295, 3), (296, 4), (297, 4), (298, 0), (299, 0), (300, 0), (301, 2), (302, 0), (303, 0), (304, 0), (305, 5), (306, 1), (307, 4), (308, 5), (309, 3), (310, 3), (311, 1), (312, 5), (313, 5), (314, 5), (315, 5), (316, 0), (317, 0), (318, 3), (319, 0), (320, 3), (321, 5), (322, 1), (323, 5), (324, 3), (325, 1), (326, 1), (327, 2), (328, 0), (329, 5), (330, 3), (331, 2), (332, 2), (333, 1), (334, 5), (335, 2), (336, 0), (337, 3), (338, 0), (339, 5), (340, 3), (341, 5), (342, 1), (343, 2), (344, 2), (345, 5), (346, 2), (347, 3), (348, 4), (349, 0), (350, 5), (351, 0), (352, 1), (353, 2), (354, 2), (355, 2), (356, 0), (357, 5), (358, 4), (359, 0), (360, 3), (361, 3), (362, 4), (363, 5), (364, 1), (365, 1), (366, 4), (367, 0), (368, 2), (369, 3), (370, 0), (371, 3), (372, 0), (373, 4), (374, 1), (375, 2), (376, 2), (377, 0), (378, 2), (379, 4), (380, 3), (381, 0), (382, 0), (383, 3), (384, 3), (385, 0), (386, 5), (387, 2), (388, 2), (389, 3), (390, 4), (391, 3), (392, 5), (393, 1), (394, 2), (395, 4), (396, 0), (397, 1), (398, 2), (399, 5), (400, 5), (401, 1), (402, 4), (403, 0), (404, 3), (405, 3), (406, 3), (407, 1), (408, 1), (409, 0), (410, 2), (411, 2), (412, 2), (413, 5), (414, 1), (415, 1), (416, 1), (417, 3), (418, 1), (419, 0), (420, 4), (421, 1), (422, 3), (423, 0), (424, 3), (425, 2), (426, 4), (427, 2), (428, 1), (429, 4), (430, 5), (431, 5), (432, 2), (433, 3), (434, 1), (435, 1), (436, 5), (437, 4), (438, 4), (439, 3), (440, 3), (441, 4), (442, 5), (443, 1), (444, 1), (445, 3), (446, 3), (447, 2), (448, 0), (449, 0), (450, 1), (451, 0), (452, 4), (453, 5), (454, 0), (455, 2), (456, 0), (457, 4), (458, 2), (459, 1), (460, 5), (461, 3), (462, 4), (463, 1), (464, 4), (465, 2), (466, 2), (467, 0), (468, 0), (469, 2), (470, 0), (471, 5), (472, 2), (473, 5), (474, 3), (475, 2), (476, 5), (477, 0), (478, 0), (479, 2), (480, 3), (481, 1), (482, 5), (483, 5), (484, 2), (485, 2), (486, 3), (487, 2), (488, 3), (489, 0), (490, 3), (491, 2), (492, 0), (493, 5), (494, 4), (495, 3), (496, 4), (497, 0), (498, 5), (499, 1)]\n"
     ]
    }
   ],
   "source": [
    "print (q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data=q_test, columns=['Id', 'Answer']).to_csv('Answer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
