{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "programs = []\n",
    "\n",
    "for i in range(1, 9):\n",
    "    program = pd.read_csv('../data/Program0%d.csv' % i)\n",
    "    \n",
    "    programs.append(program)\n",
    "    \n",
    "questions = pd.read_csv('../data/Question.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba \n",
    "#jieba.set_dictionary('../data/big5_dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jieba_line(lines):\n",
    "    cut_lines = []\n",
    "    for line in lines:\n",
    "        cut_line = jieba.lcut(line)\n",
    "        cut_lines.append(cut_line)\n",
    "        \n",
    "    return cut_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/p6/qgv6p0s53svftjnzmh6nsr7h0000gn/T/jieba.cache\n",
      "Loading model cost 1.264 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "cut_programs = []\n",
    "\n",
    "for program in programs:\n",
    "    # number of lines in the program\n",
    "    n = len(program)\n",
    "    cut_program = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        lines = program.loc[i]['Content'].split('\\n')\n",
    "        cut_program.append(jieba_line(lines))\n",
    "        \n",
    "    cut_programs.append(cut_program)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cut_questions = []\n",
    "n = len(questions)\n",
    "\n",
    "for i in range(n):\n",
    "    cut_line = []\n",
    "    cut_question = []\n",
    "    lines = questions.loc[i]['Question'].split('\\n')\n",
    "    for l in lines:\n",
    "        cut_line.append(jieba.lcut(l))\n",
    "    \n",
    "    cut_question.append(cut_line)\n",
    "    \n",
    "    for j in range(6):\n",
    "        line = questions.loc[i]['Option%d' % (j)]\n",
    "        cut_question.append(jieba.lcut(line))\n",
    "    \n",
    "    cut_questions.append(cut_question)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('../data/cut_Programs.npy', cut_programs)\n",
    "np.save('../data/cut_Questions.npy', cut_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwordset = set()\n",
    "cut_programs = np.load('../data/cut_Programs.npy')\n",
    "cut_questions = np.load('../data/cut_Questions.npy')\n",
    "#with open('../data/stopwords.txt', 'r', encoding='utf-8') as sw:\n",
    "#    for line in sw:\n",
    "#        stopwordset.add(line.strip('\\n'))\n",
    "        \n",
    "stopwordset.add('\\u3000')\n",
    "stopwordset.add('\\t')\n",
    "stopwordset.add(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 100000 lines\n",
      "Finished 200000 lines\n",
      "Finished 300000 lines\n",
      "Finished 400000 lines\n",
      "Finished 500000 lines\n",
      "Finished 600000 lines\n",
      "Finished 700000 lines\n",
      "Finished 800000 lines\n",
      "Finished 900000 lines\n",
      "Finished 1000000 lines\n",
      "Finished 1100000 lines\n",
      "Finished 1200000 lines\n",
      "Finished 1300000 lines\n",
      "Finished 1400000 lines\n",
      "Finished 1500000 lines\n",
      "Finished 1600000 lines\n",
      "Finished 1700000 lines\n",
      "Finished 1800000 lines\n",
      "Finished 1900000 lines\n",
      "Finished 2000000 lines\n",
      "Finished 2100000 lines\n",
      "Finished 2200000 lines\n",
      "Finished 2300000 lines\n",
      "2396906\n"
     ]
    }
   ],
   "source": [
    "program_out = open('program_quesiton.txt', 'w')\n",
    "text_num = 0\n",
    "\n",
    "for program in cut_programs:\n",
    "    for episode in program:\n",
    "        for line in episode:\n",
    "            ex_line = ''\n",
    "            for w in line:\n",
    "                if w not in stopwordset:\n",
    "                    ex_line += w + ' '\n",
    "            program_out.write(ex_line+'\\n')\n",
    "            text_num += 1\n",
    "            if (text_num % 100000 == 0):\n",
    "                print (\"Finished %d lines\" % text_num)\n",
    "\n",
    "print (text_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n"
     ]
    }
   ],
   "source": [
    "q_count = 0\n",
    "for question in cut_questions:\n",
    "    for i, line in enumerate(question):\n",
    "        if (i == 0):\n",
    "            ex_line = ''\n",
    "            for qline in question[i]:\n",
    "                for w in qline:\n",
    "                    if (w not in stopwordset):\n",
    "                        ex_line += w + ' '\n",
    "            program_out.write(ex_line+'\\n')\n",
    "            q_count += 1\n",
    "        else:\n",
    "            ex_line = ''\n",
    "            for w in line:\n",
    "                if w not in stopwordset:\n",
    "                    ex_line += w + ' '\n",
    "            program_out.write(ex_line+'\\n')\n",
    "            q_count += 1\n",
    "            \n",
    "print (q_count)\n",
    "program_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "sentences = word2vec.LineSentence('program_quesiton.txt')\n",
    "\n",
    "model = word2vec.Word2Vec(sentences, size=250, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('word2vec_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
